{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Intro to Web Scraping! \n", "\n", "![](https://media.giphy.com/media/1dcWGdOBg0wcU/giphy.gif)\n", "\n", "    \n", "### Today's Goals:\n", "1. Retrieve the HTML of a webpage with the `requests` library.\n", "2. Introduction to the `tree` structure of `HTML`.\n", "3. Use the `inspect` tool to sift through the HTML.\n", "4. Parse HTML with the `BeautifulSoup` library.\n", "5. Store data in a `csv` file using the `Pandas` library.\n", "\n", "# Let's scrape some data!\n", "The data we are scraping today will be from the [Quotes to Scrape](http://quotes.toscrape.com/) website.\n", "\n", "\n", "## Step 1:\n", "> **Import the necessary tools for our project**\n", "\n", "![](https://media.giphy.com/media/KcE7Dq5f8TTXzZ1LAF/giphy.gif)\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:26:54.099680Z", "start_time": "2020-12-17T16:26:53.338068Z"}}, "outputs": [], "source": ["# Webscraping\n", "import requests\n", "from bs4 import BeautifulSoup\n", "\n", "# Data organization\n", "import pandas as pd\n", "\n", "# Visualization\n", "import matplotlib.pyplot as plt\n", "plt.rcParams.update({'font.size': 22})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2\n", "> **We use the `requests` library to connect to the website we wish to scrape.**\n", "\n", "<img src='https://media.giphy.com/media/eCwAEs05phtK/giphy.gif' width='300'></img>"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:26:58.997904Z", "start_time": "2020-12-17T16:26:58.780514Z"}}, "outputs": [{"data": {"text/plain": ["<Response [200]>"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["url = 'http://quotes.toscrape.com'\n", "response = requests.get(url)\n", "response"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\u2705**A `Response 200` means our request was sucessful!** \u2705\n", "\n", "\u274cLet's take a quick look at an *unsuccessful* response. \u274c"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:01.197663Z", "start_time": "2020-12-17T16:27:01.103784Z"}}, "outputs": [{"data": {"text/plain": ["<Response [404]>"]}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": ["bad_url = 'http://quotes.toscrape.com/20'\n", "requests.get(bad_url)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**A `Response 404` means that the url you are using in your request is not pointing to a valid webpage.**\n", "\n", "<img src='https://media.giphy.com/media/VwoJkTfZAUBSU/giphy.gif' width='300'></img>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3\n", "> **We collect the html from the website by adding `.text` to the end of the response variable.** "]}, {"cell_type": "code", "execution_count": 4, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:03.768558Z", "start_time": "2020-12-17T16:27:03.764622Z"}}, "outputs": [{"data": {"text/plain": ["'<!DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n\\t<meta cha'"]}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": ["html = response.text\n", "html[:50]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4\n", "> **We use `BeautifulSoup` to turn the html into something we can manipulate.**"]}, {"cell_type": "code", "execution_count": 5, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:08.455256Z", "start_time": "2020-12-17T16:27:08.421380Z"}}, "outputs": [{"data": {"text/plain": ["<!DOCTYPE html>\n", "<html lang=\"en\">\n", "<head>\n", "<meta charset=\"utf-8\"/>\n", "<title>Quotes to Scrape</title>\n", "<link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n", "<link href=\"/static/main.css\" rel=\"stylesheet\"/>\n", "</head>\n", "<body>\n", "<div class=\"container\">\n", "<div class=\"row header-box\">\n", "<div class=\"col-md-8\">\n", "<h1>\n", "<a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n", "</h1>\n", "</div>\n", "<div class=\"col-md-4\">\n", "<p>\n", "<a href=\"/login\">Login</a>\n", "</p>\n", "</div>\n", "</div>\n", "<div class=\"row\">\n", "<div class=\"col-md-8\">\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n", "<a href=\"/author/Albert-Einstein\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"change,deep-thoughts,thinking,world\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n", "<a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n", "<a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n", "<a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n", "<a href=\"/author/J-K-Rowling\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"abilities,choices\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n", "<a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n", "<a href=\"/author/Albert-Einstein\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n", "<a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n", "<a class=\"tag\" href=\"/tag/live/page/1/\">live</a>\n", "<a class=\"tag\" href=\"/tag/miracle/page/1/\">miracle</a>\n", "<a class=\"tag\" href=\"/tag/miracles/page/1/\">miracles</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Jane Austen</small>\n", "<a href=\"/author/Jane-Austen\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"aliteracy,books,classic,humor\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/aliteracy/page/1/\">aliteracy</a>\n", "<a class=\"tag\" href=\"/tag/books/page/1/\">books</a>\n", "<a class=\"tag\" href=\"/tag/classic/page/1/\">classic</a>\n", "<a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Marilyn Monroe</small>\n", "<a href=\"/author/Marilyn-Monroe\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"be-yourself,inspirational\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/be-yourself/page/1/\">be-yourself</a>\n", "<a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cTry not to become a man of success. Rather become a man of value.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n", "<a href=\"/author/Albert-Einstein\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"adulthood,success,value\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/adulthood/page/1/\">adulthood</a>\n", "<a class=\"tag\" href=\"/tag/success/page/1/\">success</a>\n", "<a class=\"tag\" href=\"/tag/value/page/1/\">value</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cIt is better to be hated for what you are than to be loved for what you are not.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Andr\u00e9 Gide</small>\n", "<a href=\"/author/Andre-Gide\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"life,love\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n", "<a class=\"tag\" href=\"/tag/love/page/1/\">love</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cI have not failed. I've just found 10,000 ways that won't work.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Thomas A. Edison</small>\n", "<a href=\"/author/Thomas-A-Edison\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/edison/page/1/\">edison</a>\n", "<a class=\"tag\" href=\"/tag/failure/page/1/\">failure</a>\n", "<a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n", "<a class=\"tag\" href=\"/tag/paraphrased/page/1/\">paraphrased</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cA woman is like a tea bag; you never know how strong it is until it's in hot water.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Eleanor Roosevelt</small>\n", "<a href=\"/author/Eleanor-Roosevelt\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"misattributed-eleanor-roosevelt\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">misattributed-eleanor-roosevelt</a>\n", "</div>\n", "</div>\n", "<div class=\"quote\" itemscope=\"\" itemtype=\"http://schema.org/CreativeWork\">\n", "<span class=\"text\" itemprop=\"text\">\u201cA day without sunshine is like, you know, night.\u201d</span>\n", "<span>by <small class=\"author\" itemprop=\"author\">Steve Martin</small>\n", "<a href=\"/author/Steve-Martin\">(about)</a>\n", "</span>\n", "<div class=\"tags\">\n", "            Tags:\n", "            <meta class=\"keywords\" content=\"humor,obvious,simile\" itemprop=\"keywords\"/>\n", "<a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n", "<a class=\"tag\" href=\"/tag/obvious/page/1/\">obvious</a>\n", "<a class=\"tag\" href=\"/tag/simile/page/1/\">simile</a>\n", "</div>\n", "</div>\n", "<nav>\n", "<ul class=\"pager\">\n", "<li class=\"next\">\n", "<a href=\"/page/2/\">Next <span aria-hidden=\"true\">\u2192</span></a>\n", "</li>\n", "</ul>\n", "</nav>\n", "</div>\n", "<div class=\"col-md-4 tags-box\">\n", "<h2>Top Ten tags</h2>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/love/\" style=\"font-size: 28px\">love</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/inspirational/\" style=\"font-size: 26px\">inspirational</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/life/\" style=\"font-size: 26px\">life</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/humor/\" style=\"font-size: 24px\">humor</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/books/\" style=\"font-size: 22px\">books</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/reading/\" style=\"font-size: 14px\">reading</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/friendship/\" style=\"font-size: 10px\">friendship</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/friends/\" style=\"font-size: 8px\">friends</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/truth/\" style=\"font-size: 8px\">truth</a>\n", "</span>\n", "<span class=\"tag-item\">\n", "<a class=\"tag\" href=\"/tag/simile/\" style=\"font-size: 6px\">simile</a>\n", "</span>\n", "</div>\n", "</div>\n", "</div>\n", "<footer class=\"footer\">\n", "<div class=\"container\">\n", "<p class=\"text-muted\">\n", "                Quotes by: <a href=\"https://www.goodreads.com/quotes\">GoodReads.com</a>\n", "</p>\n", "<p class=\"copyright\">\n", "                Made with <span class=\"sh-red\">\u2764</span> by <a href=\"https://scrapinghub.com\">Scrapinghub</a>\n", "</p>\n", "</div>\n", "</footer>\n", "</body>\n", "</html>"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["soup = BeautifulSoup(html, 'lxml')\n", "soup"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<center><h1><b><i><u>Very Soupy</u></i></b></h1></center>\n", "\n", "The name ***Beautiful Soup*** is an appropriate description. HTML does not make for a lovely reading experience. If you feel like you're staring at complete gibberish, you're not entirely wrong! HTML is a language designed for computers, not for human eyes.\n", "\n", "<img src='https://media.giphy.com/media/5xtDarBbqdSQxfGFdNS/giphy.gif' width=\"200\"></img>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Fortunately for us,** <u>we do not have to read through every line of the html in order to web scrape.</u> \n", "\n", "Modern day web browsers come equipped with tools that allow us to easily sift through this soupy text.\n", "\n", "\n", "## Step 4\n", ">**We open up the page we're trying to scrape in a new tab.** <b><a href='http://quotes.toscrape.com/' target='_blank'>Click Here!</a></b> \ud83d\udc40"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5\n", "   > **We create a list of every `div` that has a `class` of \"quote\"**\n", "\n", "**In this instance,** every item we want to collect is divided into identically labeled containers.\n", "- A div with a class of 'quote'.\n", "\n", "Not all HTML is as well organized as this page, but HTML is basically just a bunch of different organizational containers that we use to divide up text and other forms of media. Figuring out the organizational structure of a website is the entire process for web scraping. "]}, {"cell_type": "code", "execution_count": 6, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:16.767355Z", "start_time": "2020-12-17T16:27:16.761964Z"}}, "outputs": [{"data": {"text/plain": ["10"]}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": ["quote_divs = soup.find_all('div', {'class': 'quote'})\n", "len(quote_divs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 6\n", "> **To figure out how to grab all the datapoints from a quote, we isolate a single quote, and work through the code for a single `div`.**"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:18.625508Z", "start_time": "2020-12-17T16:27:18.622898Z"}}, "outputs": [], "source": ["first_quote = quote_divs[0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### First we grab the text of the quote"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:20.425875Z", "start_time": "2020-12-17T16:27:20.421450Z"}}, "outputs": [{"data": {"text/plain": ["'\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d'"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["text = first_quote.find('span', {'class':'text'})\n", "text = text.text\n", "text"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Next we grab the author"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:22.160835Z", "start_time": "2020-12-17T16:27:22.156398Z"}}, "outputs": [{"data": {"text/plain": ["'Albert Einstein'"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["author = first_quote.find('small', {'class': 'author'})\n", "author_name = author.text\n", "author_name"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Let's also grab the link that points to the author's bio!"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:24.074956Z", "start_time": "2020-12-17T16:27:24.070308Z"}}, "outputs": [{"data": {"text/plain": ["'http://quotes.toscrape.com/author/Albert-Einstein'"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["author_link = author.findNextSibling().attrs.get('href')\n", "author_link = url + author_link\n", "author_link"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### And finally, let's grab all of the tags for the quote"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:26.627743Z", "start_time": "2020-12-17T16:27:26.622912Z"}}, "outputs": [{"data": {"text/plain": ["['change', 'deep-thoughts', 'thinking', 'world']"]}, "execution_count": 11, "metadata": {}, "output_type": "execute_result"}], "source": ["tag_container = first_quote.find('div', {'class': 'tags'})\n", "tag_links = tag_container.find_all('a')\n", "\n", "tags = []\n", "for tag in tag_links:\n", "    tags.append(tag.text)\n", "    \n", "tags"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Our data:"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:28.821452Z", "start_time": "2020-12-17T16:27:28.817331Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["text: \u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d\n", "author name:  Albert Einstein\n", "author link:  http://quotes.toscrape.com/author/Albert-Einstein\n", "tags:  ['change', 'deep-thoughts', 'thinking', 'world']\n"]}], "source": ["print('text:', text)\n", "print('author name: ', author_name)\n", "print('author link: ', author_link)\n", "print('tags: ', tags)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Step 7\n", "> We create a function to make out code reusable.\n", "\n", "Now that we know how to collect this data from a quote div, we can compile the code into a [function](https://www.geeksforgeeks.org/functions-in-python/) called `quote_data`. This allows us to grab a quote div, feed it into the function like so...\n", "> `quote_data(quote_div)`\n", "\n", "...and receive all of the data from that div."]}, {"cell_type": "code", "execution_count": 13, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:31.985897Z", "start_time": "2020-12-17T16:27:31.980192Z"}}, "outputs": [], "source": ["def quote_data(quote_div):\n", "    # Collect the quote\n", "    text = quote_div.find('span', {'class':'text'})\n", "    text = text.text\n", "    \n", "    # Collect the author name\n", "    author = quote_div.find('small', {'class': 'author'})\n", "    author_name = author.text\n", "    \n", "    # Collect author link\n", "    author_link = author.findNextSibling().attrs.get('href')\n", "    author_link = url + author_link\n", "    \n", "    # Collect tags\n", "    tag_container = quote_div.find('div', {'class': 'tags'})\n", "\n", "    tag_links = tag_container.find_all('a')\n", "\n", "    tags = []\n", "    for tag in tag_links:\n", "        tags.append(tag.text)\n", "       \n", "    # Return data as a dictionary\n", "    return {'author': author_name,\n", "            'text': text,\n", "            'author_link': author_link,\n", "            'tags': tags}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Let's test our fuction."]}, {"cell_type": "code", "execution_count": 14, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:33.968558Z", "start_time": "2020-12-17T16:27:33.964776Z"}}, "outputs": [{"data": {"text/plain": ["{'author': 'Thomas A. Edison',\n", " 'text': \"\u201cI have not failed. I've just found 10,000 ways that won't work.\u201d\",\n", " 'author_link': 'http://quotes.toscrape.com/author/Thomas-A-Edison',\n", " 'tags': ['edison', 'failure', 'inspirational', 'paraphrased']}"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["quote_data(quote_divs[7])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can collect the data from every quote on the first page with a simple [```for loop```](https://www.w3schools.com/python/python_for_loops.asp)!"]}, {"cell_type": "code", "execution_count": 15, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:36.362167Z", "start_time": "2020-12-17T16:27:36.354248Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["10 quotes scraped!\n"]}, {"data": {"text/plain": ["[{'author': 'Albert Einstein',\n", "  'text': '\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d',\n", "  'author_link': 'http://quotes.toscrape.com/author/Albert-Einstein',\n", "  'tags': ['change', 'deep-thoughts', 'thinking', 'world']},\n", " {'author': 'J.K. Rowling',\n", "  'text': '\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d',\n", "  'author_link': 'http://quotes.toscrape.com/author/J-K-Rowling',\n", "  'tags': ['abilities', 'choices']}]"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["page_one_data = []\n", "for div in quote_divs:\n", "    # Apply our function on each quote\n", "    data_from_div = quote_data(div)\n", "    page_one_data.append(data_from_div)\n", "    \n", "print(len(page_one_data), 'quotes scraped!')\n", "page_one_data[:2]"]}, {"cell_type": "markdown", "metadata": {"ExecuteTime": {"end_time": "2020-07-03T18:55:14.762708Z", "start_time": "2020-07-03T18:55:14.758667Z"}}, "source": ["# We just scraped an entire webpage!\n", "\n", "![](https://media.giphy.com/media/KiXl0vfc9XIIM/giphy.gif)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Level Up: What if we wanted to scrape the quotes from *every* page?\n", "\n", "**Step 1:** The first thing we do is take the code from above that scraped the data for all of the quotes on page one, and move it into a function called `scrape_page`."]}, {"cell_type": "code", "execution_count": 16, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:40.094311Z", "start_time": "2020-12-17T16:27:40.091017Z"}}, "outputs": [], "source": ["def scrape_page(quote_divs):\n", "    data = []\n", "    for div in quote_divs:\n", "        div_data = quote_data(div)\n", "        data.append(div_data)\n", "        \n", "    return data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Step 2:** We grab the code we used at the very beginning to collect the html and the list of divs from a web page."]}, {"cell_type": "code", "execution_count": 17, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:42.233756Z", "start_time": "2020-12-17T16:27:42.121707Z"}}, "outputs": [], "source": ["base_url = 'http://quotes.toscrape.com'\n", "response = requests.get(url)\n", "html = response.text\n", "soup = BeautifulSoup(html, 'lxml')\n", "quote_divs = soup.find_all('div', {'class': 'quote'})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Step 3:** We feed all of the `quote_divs` into our newly made `parse_page` function to grab all of the data from that page."]}, {"cell_type": "code", "execution_count": 18, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:44.295263Z", "start_time": "2020-12-17T16:27:44.290917Z"}}, "outputs": [], "source": ["data = scrape_page(quote_divs)"]}, {"cell_type": "code", "execution_count": 19, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:45.535041Z", "start_time": "2020-12-17T16:27:45.531052Z"}}, "outputs": [{"data": {"text/plain": ["[{'author': 'Albert Einstein',\n", "  'text': '\u201cThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.\u201d',\n", "  'author_link': 'http://quotes.toscrape.com/author/Albert-Einstein',\n", "  'tags': ['change', 'deep-thoughts', 'thinking', 'world']},\n", " {'author': 'J.K. Rowling',\n", "  'text': '\u201cIt is our choices, Harry, that show what we truly are, far more than our abilities.\u201d',\n", "  'author_link': 'http://quotes.toscrape.com/author/J-K-Rowling',\n", "  'tags': ['abilities', 'choices']}]"]}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": ["data[:2]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Step 4:** We check to see if there is a `Next Page` button at the bottom of the page.\n", "\n", "*This requires multiple steps.*\n", "\n", "1. We grab the outer container that has a class of `pager`."]}, {"cell_type": "code", "execution_count": 20, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:48.349296Z", "start_time": "2020-12-17T16:27:48.345701Z"}}, "outputs": [], "source": ["pager = soup.find('ul', {'class': 'pager'})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If there is no pager element on the webpage, pager will be set to `None`.\n", "\n", "2. We use an if check to make sure a pager exists:"]}, {"cell_type": "code", "execution_count": 21, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:50.137545Z", "start_time": "2020-12-17T16:27:50.134535Z"}}, "outputs": [], "source": ["if pager:\n", "    next_page = pager.find('li', {'class': 'next'})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3. We then check to see if a `Next Page` button exists on the page. \n", "\n", "    - Every page has a next button except the *last* page which only has a `Previous Page` button. Basically, we're checking to see if the `Next button` exists. It it does, we \"click\" it."]}, {"cell_type": "code", "execution_count": 22, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:52.115940Z", "start_time": "2020-12-17T16:27:52.113150Z"}}, "outputs": [], "source": ["if next_page:\n", "    next_page = next_page.findChild('a')\\\n", "                         .attrs\\\n", "                         .get('href')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With most webscraping tools, \"clicking a button\" means collecting the link inside the button and making a new request.\n", "\n", "If a link is pointing to a page on the same website, the links are usually just the forward slashes that need to be added to the base website url. This is called a `relative` link.\n", "\n", "**Step 5:** Collect the relative link that points to the next page, and add it to our base_url"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:53.965250Z", "start_time": "2020-12-17T16:27:53.961511Z"}}, "outputs": [{"data": {"text/plain": ["'http://quotes.toscrape.com/page/2/'"]}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": ["next_page = url + next_page\n", "next_page"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Step 6:** We repeat the exact same process for this new link!\n", "\n", "ie:\n", "1. Make request using a url that points to the next page.\n", "2. Scrape quote divs\n", "3. Collect data from every quote div on that page\n", "4. Find the `Next page` button.\n", "5. Collect the url from the button\n", "6. Repeat\n", "\n", "So how do we do this over and over again without repeating ourselves?\n", "\n", "The first step is compile all of these steps into a new function called `scrape_quotes`.\n", "\n", "The second step is, something called `recursion`. \n", "\n", "<center><h1><u>Recursion</u></h1></center>\n", "\n", "![](https://media.giphy.com/media/l1J9R1Q7LJGSZOxFe/giphy.gif)\n", "\n", "> **Recursion** is a bit of a mind bend, so don't feel bad if it is hard to wrap your brain around. It took me a while to be able to understand recursive functions!\n", "\n", "Essentially, recursion is where we use a function inside of itself.\n", "\n", "**In this instance,** our code will be telling the computer, if there is a `Next page` button, rerun all of the code again on the page the next button points us to and check to see if there is a `Next page` button on *that* page. If there is, keep repeating the process until a `Next page` button is not found."]}, {"cell_type": "code", "execution_count": 24, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:27:58.350269Z", "start_time": "2020-12-17T16:27:58.343845Z"}}, "outputs": [], "source": ["def scrape_quotes(url):\n", "    base_url = 'http://quotes.toscrape.com'\n", "    response = requests.get(url)\n", "    html = response.text\n", "    soup = BeautifulSoup(html, 'lxml')\n", "    quote_divs = soup.find_all('div', {'class': 'quote'})\n", "    data = scrape_page(quote_divs)\n", "    \n", "    pager = soup.find('ul', {'class': 'pager'})\n", "    if pager:\n", "        next_page = pager.find('li', {'class': 'next'})\n", "        \n", "        if next_page:\n", "            next_page =  next_page.findChild('a')\\\n", "                                  .attrs\\\n", "                                  .get('href')\n", "            \n", "            next_page = base_url + next_page\n", "            print('Scraping', next_page)\n", "            ## This is where the recursion happens\n", "            data += scrape_quotes(next_page)\n", "   \n", "    return data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can set a variable called `data` that is the output of our recursive function!\n", "\n", "> A print statement has been added to output what page is being scraped"]}, {"cell_type": "code", "execution_count": 25, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:28:01.312303Z", "start_time": "2020-12-17T16:28:00.269651Z"}}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Scraping http://quotes.toscrape.com/page/2/\n", "Scraping http://quotes.toscrape.com/page/3/\n", "Scraping http://quotes.toscrape.com/page/4/\n", "Scraping http://quotes.toscrape.com/page/5/\n", "Scraping http://quotes.toscrape.com/page/6/\n", "Scraping http://quotes.toscrape.com/page/7/\n", "Scraping http://quotes.toscrape.com/page/8/\n", "Scraping http://quotes.toscrape.com/page/9/\n", "Scraping http://quotes.toscrape.com/page/10/\n", "100 Quotes scraped!\n"]}], "source": ["data = scrape_quotes(url)\n", "print(len(data), 'Quotes scraped!')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now we can visualize and explore our data!"]}, {"cell_type": "code", "execution_count": 26, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:28:08.479899Z", "start_time": "2020-12-17T16:28:08.199162Z"}}, "outputs": [{"data": {"image/png": "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\n", "text/plain": ["<Figure size 720x432 with 1 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["def count_tags(quote):\n", "    return len(quote['tags'])\n", "\n", "def tag_lengths(data):\n", "    lengths = []\n", "    for quote in data:\n", "        lengths.append(count_tags(quote))\n", "        \n", "    return lengths\n", "        \n", "lengths = tag_lengths(data)\n", "plt.figure(figsize=(10,6))   \n", "plt.hist(lengths, bins=9)\n", "plt.title('Number of Tags');"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Saving our data\n", "\n", "There are multiple ways to save data to a file. Pandas, `The Excel of Python` allows us to do this easily."]}, {"cell_type": "code", "execution_count": 28, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:28:26.646855Z", "start_time": "2020-12-17T16:28:26.633418Z"}}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>author</th>\n", "      <th>text</th>\n", "      <th>author_link</th>\n", "      <th>tags</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Albert Einstein</td>\n", "      <td>\u201cThe world as we have created it is a process ...</td>\n", "      <td>http://quotes.toscrape.com/author/Albert-Einstein</td>\n", "      <td>[change, deep-thoughts, thinking, world]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>J.K. Rowling</td>\n", "      <td>\u201cIt is our choices, Harry, that show what we t...</td>\n", "      <td>http://quotes.toscrape.com/author/J-K-Rowling</td>\n", "      <td>[abilities, choices]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Albert Einstein</td>\n", "      <td>\u201cThere are only two ways to live your life. On...</td>\n", "      <td>http://quotes.toscrape.com/author/Albert-Einstein</td>\n", "      <td>[inspirational, life, live, miracle, miracles]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Jane Austen</td>\n", "      <td>\u201cThe person, be it gentleman or lady, who has ...</td>\n", "      <td>http://quotes.toscrape.com/author/Jane-Austen</td>\n", "      <td>[aliteracy, books, classic, humor]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Marilyn Monroe</td>\n", "      <td>\u201cImperfection is beauty, madness is genius and...</td>\n", "      <td>http://quotes.toscrape.com/author/Marilyn-Monroe</td>\n", "      <td>[be-yourself, inspirational]</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["            author                                               text  \\\n", "0  Albert Einstein  \u201cThe world as we have created it is a process ...   \n", "1     J.K. Rowling  \u201cIt is our choices, Harry, that show what we t...   \n", "2  Albert Einstein  \u201cThere are only two ways to live your life. On...   \n", "3      Jane Austen  \u201cThe person, be it gentleman or lady, who has ...   \n", "4   Marilyn Monroe  \u201cImperfection is beauty, madness is genius and...   \n", "\n", "                                         author_link  \\\n", "0  http://quotes.toscrape.com/author/Albert-Einstein   \n", "1      http://quotes.toscrape.com/author/J-K-Rowling   \n", "2  http://quotes.toscrape.com/author/Albert-Einstein   \n", "3      http://quotes.toscrape.com/author/Jane-Austen   \n", "4   http://quotes.toscrape.com/author/Marilyn-Monroe   \n", "\n", "                                             tags  \n", "0        [change, deep-thoughts, thinking, world]  \n", "1                            [abilities, choices]  \n", "2  [inspirational, life, live, miracle, miracles]  \n", "3              [aliteracy, books, classic, humor]  \n", "4                    [be-yourself, inspirational]  "]}, "execution_count": 28, "metadata": {}, "output_type": "execute_result"}], "source": ["df = pd.DataFrame(data)\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.to_csv('quotes_data.csv', index=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Scraping Tables with Pandas"]}, {"cell_type": "code", "execution_count": 29, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:28:34.397138Z", "start_time": "2020-12-17T16:28:33.883878Z"}}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>State</th>\n", "      <th>Portrait</th>\n", "      <th>Senator</th>\n", "      <th>Party</th>\n", "      <th>Party.1</th>\n", "      <th>Born</th>\n", "      <th>Occupation(s)</th>\n", "      <th>Previousoffice(s)</th>\n", "      <th>Assumed office</th>\n", "      <th>Term up</th>\n", "      <th>Residence</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Alabama</td>\n", "      <td>NaN</td>\n", "      <td>Richard Shelby</td>\n", "      <td>NaN</td>\n", "      <td>Republican</td>\n", "      <td>(age\u00a086)</td>\n", "      <td>Lawyer</td>\n", "      <td>U.S. HouseAlabama Senate</td>\n", "      <td>January 3, 1987</td>\n", "      <td>2022</td>\n", "      <td>Tuscaloosa[2]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Alabama</td>\n", "      <td>NaN</td>\n", "      <td>Doug Jones</td>\n", "      <td>NaN</td>\n", "      <td>Democratic</td>\n", "      <td>(age\u00a066)</td>\n", "      <td>Lawyer</td>\n", "      <td>Staff counsel, U.S. Senate Judiciary Committee...</td>\n", "      <td>January 3, 2018[d]</td>\n", "      <td>2020</td>\n", "      <td>Birmingham[2]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Alaska</td>\n", "      <td>NaN</td>\n", "      <td>Lisa Murkowski</td>\n", "      <td>NaN</td>\n", "      <td>Republican</td>\n", "      <td>(age\u00a063)</td>\n", "      <td>Lawyer</td>\n", "      <td>Alaska House of Representatives</td>\n", "      <td>December 20, 2002</td>\n", "      <td>2022</td>\n", "      <td>Anchorage[4]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>3</th>\n", "      <td>Alaska</td>\n", "      <td>NaN</td>\n", "      <td>Dan Sullivan</td>\n", "      <td>NaN</td>\n", "      <td>Republican</td>\n", "      <td>(age\u00a056)</td>\n", "      <td>U.S. Marine Corps officerLawyer</td>\n", "      <td>Alaska Attorney GeneralAssistant Secretary of ...</td>\n", "      <td>January 3, 2015</td>\n", "      <td>2026</td>\n", "      <td>Anchorage[4]</td>\n", "    </tr>\n", "    <tr>\n", "      <th>4</th>\n", "      <td>Arizona</td>\n", "      <td>NaN</td>\n", "      <td>Kyrsten Sinema</td>\n", "      <td>NaN</td>\n", "      <td>Democratic</td>\n", "      <td>(age\u00a044)</td>\n", "      <td>Social workerPolitical activistLawyerCollege p...</td>\n", "      <td>U.S. HouseArizona SenateArizona House of Repre...</td>\n", "      <td>January 3, 2019</td>\n", "      <td>2024</td>\n", "      <td>Phoenix[5]</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["     State  Portrait         Senator  Party     Party.1      Born  \\\n", "0  Alabama       NaN  Richard Shelby    NaN  Republican  (age\u00a086)   \n", "1  Alabama       NaN      Doug Jones    NaN  Democratic  (age\u00a066)   \n", "2   Alaska       NaN  Lisa Murkowski    NaN  Republican  (age\u00a063)   \n", "3   Alaska       NaN    Dan Sullivan    NaN  Republican  (age\u00a056)   \n", "4  Arizona       NaN  Kyrsten Sinema    NaN  Democratic  (age\u00a044)   \n", "\n", "                                       Occupation(s)  \\\n", "0                                             Lawyer   \n", "1                                             Lawyer   \n", "2                                             Lawyer   \n", "3                    U.S. Marine Corps officerLawyer   \n", "4  Social workerPolitical activistLawyerCollege p...   \n", "\n", "                                   Previousoffice(s)      Assumed office  \\\n", "0                           U.S. HouseAlabama Senate     January 3, 1987   \n", "1  Staff counsel, U.S. Senate Judiciary Committee...  January 3, 2018[d]   \n", "2                    Alaska House of Representatives   December 20, 2002   \n", "3  Alaska Attorney GeneralAssistant Secretary of ...     January 3, 2015   \n", "4  U.S. HouseArizona SenateArizona House of Repre...     January 3, 2019   \n", "\n", "  Term up      Residence  \n", "0    2022  Tuscaloosa[2]  \n", "1    2020  Birmingham[2]  \n", "2    2022   Anchorage[4]  \n", "3    2026   Anchorage[4]  \n", "4    2024     Phoenix[5]  "]}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": ["url = 'https://en.wikipedia.org/wiki/List_of_current_United_States_senators'\n", "pd.read_html(url, attrs={'id': 'senators'})[0].head()"]}, {"cell_type": "markdown", "metadata": {"ExecuteTime": {"end_time": "2020-12-17T14:57:27.424147Z", "start_time": "2020-12-17T14:57:26.425891Z"}}, "source": ["Pandas `read_html` is a really handy tool, but it isn't perfect. You'll notice that the resulting table above is quite messy. The urls for the portrait column are replaced 'NaN' values, the Born column is returning the age of the senator instead of their birth date, the occupation and previous office columns are lists inside strings with the spacing between letters removed. For this table, if we wanted to take full advantage of the available data, we would need to scrape this table by hand.  \n", "\n", "To do that, we can begin by isolating the table, and then isolating the data rows in the table.\n", "\n", "Below is a function that returns a cleaned version of the senators table."]}, {"cell_type": "code", "execution_count": 30, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:28:39.734008Z", "start_time": "2020-12-17T16:28:39.718649Z"}}, "outputs": [], "source": ["def scrape_senate_table():\n", "    # Connect to the wikipedia page\n", "    response = requests.get('https://en.wikipedia.org/wiki/List_of_current_United_States_senators')\n", "    # Collect the html from the page\n", "    html = response.text\n", "    # Parse the html with BeautifulSoup\n", "    soup = BeautifulSoup(html)\n", "    # Find the senators table\n", "    table = soup.find('table', {'id': 'senators'})\n", "    \n", "    # The first row in the table contains the column names.\n", "    # Isolate the first row\n", "    rows = table.find_all('tr')[1:]\n", "    # Create an empty list to append the row data to\n", "    senate_data = []\n", "    # Create some cleaning functions for text data\n", "    remove_new_line = lambda x: x.replace('\\n', '')\n", "    split_new_line = lambda x: x.split('\\n')\n", "    \n", "    # Loop over each row\n", "    for row in rows:\n", "        # find all td tags from the row\n", "        td_tags = row.find_all('td')\n", "        # The senators table merges the cell for `state name` so it spans both \n", "        # senators from a state. \n", "        # When parsing the html, the state name only appears for the senator\n", "        # that appears first in the table, and the second appearing senator has \n", "        # one less td tag.\n", "        # Because of this we need to check the length of the td tags\n", "        # If there is one less tag, we use the state name from the previous iteration\n", "        if len(td_tags) == 10:\n", "            previous_element = [td_tags[0]]\n", "        else:\n", "            previous_element += td_tags\n", "            td_tags = previous_element\n", "        \n", "        # Collect the state name\n", "        state = remove_new_line(td_tags[0].text)\n", "        # Collect the image url\n", "        image = td_tags[1].find('img').attrs['src']\n", "        # Collect the name of the senator\n", "        name = remove_new_line(row.find('th').text)\n", "        # Collect the css color string for the political party\n", "        party_color = td_tags[2].attrs['style'].split(':')[-1]\n", "        # Collect the party name\n", "        party_name = remove_new_line(td_tags[3].text)\n", "        # Collect the date of birth\n", "        dob = ' '.join(remove_new_line(td_tags[4]\\\n", "                                       .text)\\\n", "                                       .strip()\\\n", "                                       .split(' ')[1:4])\n", "        # Collect the occupation\n", "        occupation = split_new_line(BeautifulSoup(str(td_tags[5])\\\n", "                                                  .replace('<br/>', '\\n'))\\\n", "                                                  .td\\\n", "                                                  .text)\n", "        # If only one occupation is present\n", "        # Pull that occupation out of the list\n", "        # And return a single string\n", "        if occupation[1] == '':\n", "            occupation = occupation[0]\n", "        # Collect the previous office\n", "        previous_office = split_new_line(BeautifulSoup(str(td_tags[6])\\\n", "                                                       .replace('<br/>', '\\n'))\\\n", "                                                       .td\\\n", "                                                      .text)\n", "        # If only one previous office is present\n", "        # Pull that value out of the list\n", "        # And return a single string\n", "        if previous_office[1] == '':\n", "            previous_office = previous_office[0]\n", "        # Collect assumed office\n", "        assumed_office = remove_new_line(td_tags[7].text)\n", "        # Collect the end of their term\n", "        term_up = remove_new_line(td_tags[8].text)\n", "        # Collect their residence\n", "        residence = split_new_line(td_tags[9].text)\n", "        \n", "        # If only one residence is present\n", "        # Pull that value out of the list\n", "        # And return a single string\n", "        if residence[1] == '':\n", "            residence = residence[0]\n", "            # Many of the residences have a \n", "            # link pointing to additional information\n", "            # We do not need this\n", "            if '[' in residence:\n", "                residence = residence[:-3]\n", "        # Create data dictionary\n", "        collected = {'state': state, 'name': name,'dob': dob, 'party': party_name,\n", "                    'party_color': party_color,\n", "                    'occupation': occupation,\n", "                    'previous_office': previous_office,\n", "                    'assumed_office': assumed_office,\n", "                    'term_up': term_up, 'residence': residence,\n", "                    'portrait': image}\n", "        # Append dictionary to the senate_data list\n", "        senate_data.append(collected)\n", "        \n", "    # Once data from all rows has been collected\n", "    # return the data as a pandas dataframe\n", "    return pd.DataFrame(senate_data)"]}, {"cell_type": "code", "execution_count": 31, "metadata": {"ExecuteTime": {"end_time": "2020-12-17T16:28:41.719396Z", "start_time": "2020-12-17T16:28:41.324677Z"}}, "outputs": [{"data": {"text/html": ["<div>\n", "<style scoped>\n", "    .dataframe tbody tr th:only-of-type {\n", "        vertical-align: middle;\n", "    }\n", "\n", "    .dataframe tbody tr th {\n", "        vertical-align: top;\n", "    }\n", "\n", "    .dataframe thead th {\n", "        text-align: right;\n", "    }\n", "</style>\n", "<table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", "    <tr style=\"text-align: right;\">\n", "      <th></th>\n", "      <th>state</th>\n", "      <th>name</th>\n", "      <th>dob</th>\n", "      <th>party</th>\n", "      <th>party_color</th>\n", "      <th>occupation</th>\n", "      <th>previous_office</th>\n", "      <th>assumed_office</th>\n", "      <th>term_up</th>\n", "      <th>residence</th>\n", "      <th>portrait</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "    <tr>\n", "      <th>0</th>\n", "      <td>Alabama</td>\n", "      <td>Richard Shelby</td>\n", "      <td>May 6, 1934</td>\n", "      <td>Republican</td>\n", "      <td>#E81B23</td>\n", "      <td>Lawyer</td>\n", "      <td>[U.S. House, Alabama Senate, ]</td>\n", "      <td>January 3, 1987</td>\n", "      <td>2022</td>\n", "      <td>Tuscaloosa</td>\n", "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>1</th>\n", "      <td>Alabama</td>\n", "      <td>Doug Jones</td>\n", "      <td>May 4, 1954</td>\n", "      <td>Democratic</td>\n", "      <td>#3333FF</td>\n", "      <td>Lawyer</td>\n", "      <td>[Staff counsel, U.S. Senate Judiciary Committe...</td>\n", "      <td>January 3, 2018[d]</td>\n", "      <td>2020</td>\n", "      <td>Birmingham</td>\n", "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n", "    </tr>\n", "    <tr>\n", "      <th>2</th>\n", "      <td>Alaska</td>\n", "      <td>Lisa Murkowski</td>\n", "      <td>May 22, 1957</td>\n", "      <td>Republican</td>\n", "      <td>#E81B23</td>\n", "      <td>Lawyer</td>\n", "      <td>Alaska House of Representatives</td>\n", "      <td>December 20, 2002</td>\n", "      <td>2022</td>\n", "      <td>Anchorage</td>\n", "      <td>//upload.wikimedia.org/wikipedia/commons/thumb...</td>\n", "    </tr>\n", "  </tbody>\n", "</table>\n", "</div>"], "text/plain": ["     state            name           dob       party party_color occupation  \\\n", "0  Alabama  Richard Shelby   May 6, 1934  Republican     #E81B23     Lawyer   \n", "1  Alabama      Doug Jones   May 4, 1954  Democratic     #3333FF     Lawyer   \n", "2   Alaska  Lisa Murkowski  May 22, 1957  Republican     #E81B23     Lawyer   \n", "\n", "                                     previous_office      assumed_office  \\\n", "0                     [U.S. House, Alabama Senate, ]     January 3, 1987   \n", "1  [Staff counsel, U.S. Senate Judiciary Committe...  January 3, 2018[d]   \n", "2                    Alaska House of Representatives   December 20, 2002   \n", "\n", "  term_up   residence                                           portrait  \n", "0    2022  Tuscaloosa  //upload.wikimedia.org/wikipedia/commons/thumb...  \n", "1    2020  Birmingham  //upload.wikimedia.org/wikipedia/commons/thumb...  \n", "2    2022   Anchorage  //upload.wikimedia.org/wikipedia/commons/thumb...  "]}, "execution_count": 31, "metadata": {}, "output_type": "execute_result"}], "source": ["scrape_senate_table().head(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Web scraping is a powerful tool. \n", "\n", "It can be used:\n", "- To discover the most in demand skills for thousands of online job postings.\n", "- To learn the average price of a product from thousands of online sale.\n", "- To research social media networks.\n", "\n", "**And so much more!** As our world continues to develop online markets and communities, the uses for webscraping continue to grow. In the end, the power of web scraping comes from the ability to create datasets that otherwise do not exist, or at the very least, are not readily available to the public.\n"]}], "metadata": {"hide_input": false, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {"height": "calc(100% - 180px)", "left": "10px", "top": "150px", "width": "303.797px"}, "toc_section_display": true, "toc_window_display": false}, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}, "nbformat": 4, "nbformat_minor": 2}